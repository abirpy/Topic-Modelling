{"cells":[{"cell_type":"code","source":["import json\nimport sparknlp\n\nsparknlp.start()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"64433e61-0b71-4812-ac87-58f4109ea1f1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[5]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[5]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"/?o=2267446239642753#setting/sparkui/1029-142955-8nqmz3mz/driver-7135002351721295314\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.1.2</code></dd>\n              <dt>Master</dt>\n                <dd><code>spark://10.166.247.57:7077</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Databricks Shell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        ","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"/?o=2267446239642753#setting/sparkui/1029-142955-8nqmz3mz/driver-7135002351721295314\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.1.2</code></dd>\n              <dt>Master</dt>\n                <dd><code>spark://10.166.247.57:7077</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Databricks Shell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        "]}}],"execution_count":0},{"cell_type":"code","source":["dffull = spark.read.format(\"avro\").load(\"/mnt/scratch/BParticles17701850.avro\")\ndfads = spark.read.format(\"avro\").load(\"/mnt/scratch/BPads17701850.avro\")\ndfERBM = spark.read.format(\"avro\").load(\"/mnt/scratch/BPerbm4500.avro\")\ndftiny = spark.read.format(\"avro\").load(\"/mnt/scratch/BPtinysample.avro\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b4853491-68cc-4bd3-bcd5-0a17b18d7ef7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Selecting a database and selecting three relevant fields RecordID, text, and article title\n# Change the line below to change the dataframe to work on\ndf = dffull\ndf = df.select (\"RecordID\" , \"text\", \"ArticleTitle\")\n\nprint(str(df.count()) + \" articles available in the dataset\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"66c9af13-5446-4e6d-82ad-01d11b5f4d7d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">981990 articles available in the dataset\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">981990 articles available in the dataset\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Filtering the dataframe based on the presence of certain words in the text\nfilteredDf = df.filter((df.text.rlike('(?i)libel')) & ( df.text.rlike('(?i)court') \n                      | df.text.rlike('(?i)case') | df.text.rlike('(?i)legal') \n                      | df.text.rlike('(?i)jury')))\n\nnumTexts = filteredDf.count()\n\nprint(str(numTexts) + \" articles available in the filtered dataset\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e15070c3-e061-448f-aedb-64ec4acad1ab"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">13036 articles available in the filtered dataset\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">13036 articles available in the filtered dataset\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["import sparknlp\nfrom sparknlp.base import *\nfrom sparknlp.annotator import *\nfrom sparknlp.pretrained import PretrainedPipeline\nfrom pyspark.ml import Pipeline, PipelineModel\n\n\ndocumentAssembler = DocumentAssembler() \\\n    .setInputCol(\"text\") \\\n    .setOutputCol(\"document\")\n\nsentenceDetector = SentenceDetector() \\\n    .setInputCols([\"document\"]) \\\n    .setOutputCol(\"sentence\")\n\nregexTokenizer = Tokenizer() \\\n    .setInputCols([\"sentence\"]) \\\n    .setOutputCol(\"token\") \\\n    .setTargetPattern(\"\\w+\") \\\n    .setMinLength(3)  # splits at any non-alphanumeric character\n\nstop_words = StopWordsCleaner.pretrained(\"stopwords_en\", \"en\") \\\n    .setInputCols([\"token\"]) \\\n    .setOutputCol(\"cleanTokens\")\n\nnormalizer = Normalizer() \\\n    .setInputCols([\"cleanTokens\"]) \\\n    .setOutputCol(\"normalized\") \\\n    .setLowercase(True)\n\nlemmatizer = LemmatizerModel.pretrained() \\\n    .setInputCols([\"normalized\"]) \\\n    .setOutputCol(\"lemma\")\n\nfinisher = Finisher() \\\n    .setInputCols([\"lemma\"]) \\\n    .setIncludeMetadata(True)\n\npipeline = Pipeline().setStages([\n    documentAssembler,\n    sentenceDetector,\n    regexTokenizer,\n    stop_words,\n    normalizer,\n    lemmatizer,\n    finisher \n])"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2e7e7635-7c8a-462e-be51-edfa58c5cec2"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">stopwords_en download started this may take some time.\nApproximate size to download 2.9 KB\n\r[ | ]\r[OK!]\nlemma_antbnc download started this may take some time.\nApproximate size to download 907.6 KB\n\r[ | ]\r[OK!]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">stopwords_en download started this may take some time.\nApproximate size to download 2.9 KB\n\r[ | ]\r[OK!]\nlemma_antbnc download started this may take some time.\nApproximate size to download 907.6 KB\n\r[ | ]\r[OK!]\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["tokenized_df = pipeline.fit(filteredDf).transform(filteredDf)\ntokenized_df.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6293df74-c1d5-4e44-abf0-a8491cbbe50e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">root\n |-- RecordID: string (nullable = true)\n |-- text: string (nullable = true)\n |-- ArticleTitle: string (nullable = true)\n |-- finished_lemma: array (nullable = true)\n |    |-- element: string (containsNull = true)\n |-- finished_lemma_metadata: array (nullable = true)\n |    |-- element: struct (containsNull = true)\n |    |    |-- _1: string (nullable = true)\n |    |    |-- _2: string (nullable = true)\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- RecordID: string (nullable = true)\n-- text: string (nullable = true)\n-- ArticleTitle: string (nullable = true)\n-- finished_lemma: array (nullable = true)\n    |-- element: string (containsNull = true)\n-- finished_lemma_metadata: array (nullable = true)\n    |-- element: struct (containsNull = true)\n    |    |-- _1: string (nullable = true)\n    |    |-- _2: string (nullable = true)\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Documentation - https://radimrehurek.com/gensim/auto_examples/index.html#core-tutorials-new-users-start-here\n# Helpful sections - Corpora and Vector Spaces, Topics and Transformations\n\nfrom gensim import corpora, models\n\n# An array of arrays with each sub-array representing the list of lemma \n# found in a single document\ntexts = [row['finished_lemma'] for row in tokenized_df.take(3000)]\n\n# Storing all words in a dictionary that will be used to assign the same unique\n# token id to a word across all documents \ndct = corpora.Dictionary(texts)\n\n# Stores the frequencies of all words occuring in a text as a sparse vector\n# Ex. if a word 'libel' occurs 5 times in document 1 and is assigned an unique id of\n# 23, corpus[0] will contain (23, 5). Use dct.token2id to see what id is assigned to a word\ncorpus = [dct.doc2bow(text) for text in texts]\n\ntfidf = models.TfidfModel(corpus) # initialize a model\n\ncorpus_tfidf = tfidf[corpus]\n\nlsi_model = models.LsiModel(corpus_tfidf, id2word= dct, num_topics=300)  # initialize an LSI transformation\ncorpus_lsi = lsi_model[corpus_tfidf]  # create a double wrapper over the original corpus: bow->tfidf->fold-in-lsi\n\ntopics = lsi_model.print_topics(300)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a379158e-ed4c-4b1a-89e5-c4b3cf936a87"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Iterating over list of correlation between each documents and all topics\n# Each doc in this format [(0, 0.06600783396090518), (1, -0.520070330636184)]\ndocuments = []\nfor doc in corpus_lsi:\n  topicMatrix = []\n  for topic in doc:\n    topicMatrix.append((topics[topic[0]], topic[1] if topic[1] > 0 else -topic[1]))\n    \n  topicMatrix.sort(key = lambda x: x[1], reverse=True) # sort in descending order to get more related documents in front of list\n  \n  documents.append(topicMatrix)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8208df62-4871-4c96-8dd1-012f35f234f3"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["from pprint import pprint\n\ndocumentIdx = 0\nnumTopics = 5\n\npprint(documents[documentIdx][:numTopics]) # Prints 5 most related topics for that document"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"620ba071-1626-47e8-9ede-bc8bcc01e6b4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">[((0,\n   &#39;0.113*&#34;thc&#34; + 0.083*&#34;tbe&#34; + 0.075*&#34;house&#34; + 0.072*&#34;church&#34; + 0.067*&#34;bill&#34; &#39;\n   &#39;+ 0.060*&#34;thle&#34; + 0.060*&#34;government&#34; + 0.059*&#34;tile&#34; + 0.058*&#34;lord&#34; + &#39;\n   &#39;0.055*&#34;catholic&#34;&#39;),\n  0.0791402522074277),\n ((9,\n   &#39;0.457*&#34;tbe&#34; + -0.204*&#34;anel&#34; + 0.156*&#34;tbat&#34; + 0.121*&#34;defendant&#34; + &#39;\n   &#39;0.120*&#34;tba&#34; + -0.115*&#34;sentence&#34; + 0.110*&#34;aad&#34; + 0.105*&#34;waa&#34; + &#39;\n   &#39;0.103*&#34;catholic&#34; + 0.093*&#34;plaintiff&#34;&#39;),\n  0.07449800313043035),\n ((261,\n   &#39;-0.044*&#34;rubric&#34; + 0.044*&#34;wilkins&#34; + -0.041*&#34;locke&#34; + 0.039*&#34;kirk&#34; + &#39;\n   &#39;-0.038*&#34;menemy&#34; + 0.037*&#34;jack&#34; + -0.036*&#34;cortes&#34; + -0.036*&#34;chairman&#34; + &#39;\n   &#39;-0.035*&#34;beard&#34; + -0.033*&#34;sidney&#34;&#39;),\n  0.06664723933089502),\n ((16,\n   &#39;0.298*&#34;tbe&#34; + -0.264*&#34;thc&#34; + -0.234*&#34;plaintiff&#34; + -0.212*&#34;defendant&#34; + &#39;\n   &#39;-0.210*&#34;xvas&#34; + -0.154*&#34;catholic&#34; + 0.151*&#34;anel&#34; + 0.145*&#34;petitioner&#34; + &#39;\n   &#39;0.111*&#34;tbat&#34; + 0.110*&#34;slave&#34;&#39;),\n  0.061764967461246024),\n ((213,\n   &#39;-0.058*&#34;wakefield&#34; + 0.051*&#34;chap&#34; + 0.050*&#34;kean&#34; + 0.047*&#34;parr&#34; + &#39;\n   &#39;0.045*&#34;dissenter&#34; + -0.043*&#34;phillips&#34; + -0.043*&#34;artery&#34; + -0.042*&#34;memoir&#34; &#39;\n   &#39;+ -0.040*&#34;canada&#34; + -0.038*&#34;prynne&#34;&#39;),\n  0.05796641714611582)]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[((0,\n   &#39;0.113*&#34;thc&#34; + 0.083*&#34;tbe&#34; + 0.075*&#34;house&#34; + 0.072*&#34;church&#34; + 0.067*&#34;bill&#34; &#39;\n   &#39;+ 0.060*&#34;thle&#34; + 0.060*&#34;government&#34; + 0.059*&#34;tile&#34; + 0.058*&#34;lord&#34; + &#39;\n   &#39;0.055*&#34;catholic&#34;&#39;),\n  0.0791402522074277),\n ((9,\n   &#39;0.457*&#34;tbe&#34; + -0.204*&#34;anel&#34; + 0.156*&#34;tbat&#34; + 0.121*&#34;defendant&#34; + &#39;\n   &#39;0.120*&#34;tba&#34; + -0.115*&#34;sentence&#34; + 0.110*&#34;aad&#34; + 0.105*&#34;waa&#34; + &#39;\n   &#39;0.103*&#34;catholic&#34; + 0.093*&#34;plaintiff&#34;&#39;),\n  0.07449800313043035),\n ((261,\n   &#39;-0.044*&#34;rubric&#34; + 0.044*&#34;wilkins&#34; + -0.041*&#34;locke&#34; + 0.039*&#34;kirk&#34; + &#39;\n   &#39;-0.038*&#34;menemy&#34; + 0.037*&#34;jack&#34; + -0.036*&#34;cortes&#34; + -0.036*&#34;chairman&#34; + &#39;\n   &#39;-0.035*&#34;beard&#34; + -0.033*&#34;sidney&#34;&#39;),\n  0.06664723933089502),\n ((16,\n   &#39;0.298*&#34;tbe&#34; + -0.264*&#34;thc&#34; + -0.234*&#34;plaintiff&#34; + -0.212*&#34;defendant&#34; + &#39;\n   &#39;-0.210*&#34;xvas&#34; + -0.154*&#34;catholic&#34; + 0.151*&#34;anel&#34; + 0.145*&#34;petitioner&#34; + &#39;\n   &#39;0.111*&#34;tbat&#34; + 0.110*&#34;slave&#34;&#39;),\n  0.061764967461246024),\n ((213,\n   &#39;-0.058*&#34;wakefield&#34; + 0.051*&#34;chap&#34; + 0.050*&#34;kean&#34; + 0.047*&#34;parr&#34; + &#39;\n   &#39;0.045*&#34;dissenter&#34; + -0.043*&#34;phillips&#34; + -0.043*&#34;artery&#34; + -0.042*&#34;memoir&#34; &#39;\n   &#39;+ -0.040*&#34;canada&#34; + -0.038*&#34;prynne&#34;&#39;),\n  0.05796641714611582)]\n</div>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Libel Cases Topic Modelling","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":644157483941358}},"nbformat":4,"nbformat_minor":0}
